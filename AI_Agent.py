import sys, os, traceback, numpy as np, sounddevice as sd
import pygame
import json
import librosa
import torch
import glob
import ssl
import warnings
import threading
import time
import uuid
import re
from scipy.io.wavfile import write as write_wav
import cv2
import face_recognition

# ==========================================
# âš™ï¸ SETTINGS
# ==========================================
TEST_TEXT_MODE = False

# âœ… IMPORT UTILS
try:
    from memory import MemorySystem
except ImportError:
    print("âŒ Error: 'memory.py' not found.")
    sys.exit(1)

try:
    import robot_gui
except ImportError:
    print("âŒ Error: 'robot_gui.py' missing.")
    sys.exit(1)

try:
    from attendance_core import AttendanceManager
except ImportError:
    print("âŒ Error: 'attendance_core.py' not found.")
    sys.exit(1)

try:
    from class_manager import ClassManager
except ImportError:
    print("âŒ Error: 'class_manager.py' not found.")
    sys.exit(1)

# --- CONFIG ---
ssl._create_default_https_context = ssl._create_unverified_context
warnings.filterwarnings("ignore")

# --- PLACEHOLDERS ---
stt_model = None
stt_processor = None
tts = None
llm = None
CURRENT_USER_ID = "Unknown"
CURRENT_USER_DISPLAY = "Unknown"
LAST_USER = None
memory_sys = MemorySystem()
attendance_sys = AttendanceManager()
class_sys = ClassManager()

# --- IMPORTS (Lazy) ---
from langchain_ollama import OllamaLLM

try:
    from faster_whisper import WhisperModel
except ImportError:
    print("Please install faster_whisper")
    sys.exit(1)
try:
    from tts import TextToSpeechService
except ImportError:
    print("âŒ Error: 'tts.py' not found.")
    sys.exit(1)

# --- PATHS ---
if getattr(sys, 'frozen', False):
    SCRIPT_DIR = os.path.dirname(sys.executable)
else:
    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

VOICE_DIR = os.path.join(SCRIPT_DIR, 'saved_voices')
FACES_DIR = "known_faces"
os.makedirs(VOICE_DIR, exist_ok=True)
os.makedirs(FACES_DIR, exist_ok=True)

ROBOT = None


# ---------------------------------------------------------
# ğŸŸ¢ PRONUNCIATION DICTIONARY (Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ØªÙ„ÙØ¸)
# ---------------------------------------------------------
def fix_pronunciation(text):
    if not text: return ""

    # Ù„ÛŒØ³Øª Ú©Ù„Ù…Ø§Øª (Ø³Ù…Øª Ú†Ù¾: Ú©Ù„Ù…Ù‡ Ù…Ø¹Ù…ÙˆÙ„ÛŒ | Ø³Ù…Øª Ø±Ø§Ø³Øª: Ú©Ù„Ù…Ù‡ Ø¨Ø§ Ø§ÙØ¹Ø±Ø§Ø¨)
    corrections = {
        # --- Ú©Ù„Ù…Ø§Øª Ø±ÙˆØ²Ù…Ø±Ù‡ ---
        "Ø³Ù„Ø§Ù…": "Ø³ÙÙ„Ø§Ù…",
        "Ø®Ø¯Ø§Ø­Ø§ÙØ¸": "Ø®ÙØ¯Ø§Ø­Ø§ÙÙØ¸",
        "Ù…Ù…Ù†ÙˆÙ†": "Ù…ÙÙ…Ù†ÙˆÙ†",
        "Ù…ØªØ´Ú©Ø±Ù…": "Ù…ÙØªÙØ´ÙÚ©Ù‘ÙØ±ÙÙ…",
        "ØªØ´Ú©Ø±": "ØªÙØ´ÙÚ©Ù‘ÙØ±",
        "Ù„Ø·ÙØ§": "Ù„ÙØ·ÙØ§Ù‹",
        "Ø­ØªÙ…Ø§": "Ø­ÙØªÙ…Ø§Ù‹",
        "Ø®ÛŒÙ„ÛŒ": "Ø®ÙÛŒÙ„ÛŒ",
        "Ø¨Ù„Ù‡": "Ø¨ÙÙ„ÙÙ‡",
        "Ø®ÛŒØ±": "Ø®ÙÛŒØ±",
        "Ø´Ø§ÛŒØ¯": "Ø´Ø§ÛŒÙØ¯",
        "Ø§Ù„Ø¨ØªÙ‡": "Ø§ÙÙ„Ø¨ÙØªÙ‘ÙÙ‡",
        "Ú†Ø·ÙˆØ±": "Ú†ÙØ·ÙˆØ±",
        "Ú†Ú¯ÙˆÙ†Ù‡": "Ú†ÙÚ¯ÙˆÙ†ÙÙ‡",
        "Ú©Ø¬Ø§": "Ú©ÙØ¬Ø§",
        "Ú©ÛŒ": "Ú©ÙÛŒ",  # Ø²Ù…Ø§Ù†

        # --- Ù…Ø¯Ø±Ø³Ù‡ Ùˆ Ø¢Ù…ÙˆØ²Ø´ ---
        "Ù…Ø¹Ù„Ù…": "Ù…ÙØ¹ÙÙ„Ù‘ÙÙ…",
        "Ù…Ø¯Ø±Ø³Ù‡": "Ù…ÙØ¯Ø±ÙØ³ÙÙ‡",
        "Ú©Ù„Ø§Ø³": "Ú©ÙÙ„Ø§Ø³",
        "Ø¯Ø±Ø³": "Ø¯ÙØ±Ø³",
        "Ù…Ø´Ù‚": "Ù…ÙØ´Ù‚",
        "Ø§Ù…ØªØ­Ø§Ù†": "Ø§ÙÙ…ØªÙØ­Ø§Ù†",
        "Ù†Ù…Ø±Ù‡": "Ù†ÙÙ…Ø±ÙÙ‡",
        "Ø±ÛŒØ§Ø¶ÛŒ": "Ø±ÙÛŒØ§Ø¶ÛŒ",
        "Ø¹Ù„ÙˆÙ…": "Ø¹ÙÙ„ÙˆÙ…",
        "ÙØ§Ø±Ø³ÛŒ": "ÙØ§Ø±Ø³ÛŒ",
        "ØªØ§Ø±ÛŒØ®": "ØªØ§Ø±ÛŒØ®",
        "Ø¬ØºØ±Ø§ÙÛŒØ§": "Ø¬ÙØºØ±Ø§ÙÛŒØ§",
        "Ø³ÙˆØ§Ù„": "Ø³ÙÙˆØ§Ù„",
        "Ø¬ÙˆØ§Ø¨": "Ø¬ÙÙˆØ§Ø¨",
        "Ù¾Ø§Ø³Ø®": "Ù¾Ø§Ø³ÙØ®",
        "Ø¯Ø§Ù†Ø´": "Ø¯Ø§Ù†ÙØ´",
        "Ø¢Ù…ÙˆØ²": "Ø¢Ù…ÙˆØ²",

        # --- Ø§ÙØ¹Ø§Ù„ Ùˆ Ø¶Ù…Ø§ÛŒØ± ---
        " Ø§Ø³Øª ": " Ø§ÙØ³Øª ",
        " Ù‡Ø³Øª ": " Ù‡ÙØ³Øª ",
        " Ø¨ÙˆØ¯ ": " Ø¨ÙˆØ¯ ",
        " Ø´Ø¯ ": " Ø´ÙØ¯ ",
        " Ú©Ø±Ø¯ ": " Ú©ÙØ±Ø¯ ",
        " Ú¯ÙØª ": " Ú¯ÙÙØª ",
        " Ø±ÙØª ": " Ø±ÙÙØª ",
        " Ø¢Ù…Ø¯ ": " Ø¢Ù…ÙØ¯ ",
        " Ù…Ù† ": " Ù…ÙÙ† ",
        " ØªÙˆ ": " ØªÙÙˆ ",
        " Ù…Ø§ ": " Ù…Ø§ ",
        " Ø´Ù…Ø§ ": " Ø´ÙÙ…Ø§ ",

        # --- ØµÙØ§Øª Ùˆ Ø§Ø³Ù…â€ŒÙ‡Ø§ ---
        "Ø¨Ø²Ø±Ú¯": "Ø¨ÙØ²ÙØ±Ú¯",
        "Ú©ÙˆÚ†Ú©": "Ú©ÙˆÚ†ÙÚ©",
        "Ø®ÙˆØ¨": "Ø®ÙˆØ¨",
        "Ø¨Ø¯": "Ø¨ÙØ¯",
        "Ø²ÛŒØ¨Ø§": "Ø²ÛŒØ¨Ø§",
        "Ø²Ø´Øª": "Ø²ÙØ´Øª",
        "Ø³Ø±ÛŒØ¹": "Ø³ÙØ±ÛŒØ¹",
        "Ú©Ù†Ø¯": "Ú©ÙÙ†Ø¯",
        "Ù…Ù‡Ù…": "Ù…ÙÙ‡ÙÙ…",
        "Ø§Ø³Ù…": "Ø§ÙØ³Ù…",
        "Ù†Ø§Ù…": "Ù†Ø§Ù…",
        "Ú©Ø´ÙˆØ±": "Ú©ÙØ´ÙˆÙØ±",
        "Ø´Ù‡Ø±": "Ø´ÙÙ‡Ø±",
        "Ø¬Ù‡Ø§Ù†": "Ø¬ÙÙ‡Ø§Ù†",
        "Ø¯Ù†ÛŒØ§": "Ø¯ÙÙ†ÛŒØ§",
        "Ø­ÛŒÙˆØ§Ù†": "Ø­ÙÛŒÙˆØ§Ù†",
        "Ø§Ù†Ø³Ø§Ù†": "Ø§ÙÙ†Ø³Ø§Ù†",
        "Ø±Ø¨Ø§Øª": "Ø±ÙØ¨Ø§Øª",
        "Ù‡ÙˆØ´": "Ù‡ÙˆØ´Ù",
        "Ù…ØµÙ†ÙˆØ¹ÛŒ": "Ù…ÙØµÙ†ÙˆØ¹ÛŒ",
        "Ø§Ø·Ù„Ø§Ø¹Ø§Øª": "Ø§ÙØ·Ù‘ÙÙ„Ø§Ø¹Ø§Øª",
        "ÙˆÛŒÚ˜Ú¯ÛŒ": "ÙˆÛŒÚ˜ÙÚ¯ÛŒ",

        # --- Ú©Ù„Ù…Ø§Øª Ø®Ø§Øµ ---
        "Ú©Ø±Ú¯Ø¯Ù†": "Ú©ÙØ±Ú¯ÙØ¯ÙÙ†",
        "Ø§Ù…ÛŒÙ†": "Ø§ÙÙ…ÛŒÙ†",
        "Ø§ÛŒØ±Ø§Ù†": "Ø§ÛŒØ±Ø§Ù†",
        "Ø¢Ù„Ù…Ø§Ù†": "Ø¢Ù„Ù…Ø§Ù†",
        "ÙØ±Ø§Ù†Ø³Ù‡": "ÙÙØ±Ø§Ù†Ø³Ù‡",
        "Ø²Ø±Ø§ÙÙ‡": "Ø²ÙØ±Ø§ÙÙ‡",
        "Ø®Ø±Ø³": "Ø®ÙØ±Ø³",
        "Ú¯Ø±Ø¨Ù‡": "Ú¯ÙØ±Ø¨Ù‡",
        "Ø´ØªØ±": "Ø´ÙØªÙØ±",
        "Ú©Ø±ÙˆÚ©Ø¯ÛŒÙ„": "Ú©ÙØ±ÙˆÚ©ÙØ¯ÛŒÙ„",
        "Ù…Ø±Ø¨Ø¹": "Ù…ÙØ±ÙØ¨Ù‘Ø¹",
        "Ù…Ø³ØªØ·ÛŒÙ„": "Ù…ÙØ³Ø·ÙØªÛŒÙ„",
        "Ø®ÙˆØ§Ù‡Ø±": "Ø®ÙˆÙØ§Ù‡ÙØ±",
        "Ø®ÙˆØ§Ø¨": "Ø®ÙˆÙØ§Ø¨",
        "Ú©Ø±Ù…": "Ú©ÙØ±Ù…",
        "Ú¯Ù„": "Ú¯ÙÙ„",
        "Ú†Ù‡Ø§Ø±Ù¾Ø§ÛŒÙ‡":"Ú†Ø§Ù‡Ø§Ø±Ù¾Ø§"
    }

    # Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ú©Ù„Ù…Ø§Øª
    for wrong, correct in corrections.items():
        text = text.replace(f" {wrong} ", f" {correct} ")
        if text.startswith(wrong + " "):
            text = text.replace(wrong + " ", correct + " ", 1)
        if text.endswith(" " + wrong):
            text = text[:-len(wrong)] + correct
        if text == wrong:
            text = correct

    return text


# ---------------------------------------------------------
# SMART HISTORY
# ---------------------------------------------------------
def get_smart_history(unique_id):
    json_path = os.path.join("robot_memory", f"{unique_id}.json")
    if not os.path.exists(json_path): return ""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        if not data: return ""
        selected = data[-6:]
        txt = []
        for e in selected:
            if not e.get('user') or not e.get('ai'): continue
            txt.append(f"User: {e.get('user')}\nAssistant: {e.get('ai')}")
        return "\n".join(txt)
    except:
        return ""


# ---------------------------------------------------------
# RECORDER & STT
# ---------------------------------------------------------
class Recorder:
    def __init__(self):
        self.dev = 22
        self.rate = 48000
        self.channels = 2
        self.dtype = 'float32'
        self.data = []
        self.stream = None

    def _convert_to_whisper_format(self, audio_data):
        try:
            if audio_data.ndim > 1:
                audio_data = audio_data.mean(axis=1)
            if self.rate != 16000:
                audio_data = librosa.resample(audio_data, orig_sr=self.rate, target_sr=16000)
            return audio_data.flatten()
        except Exception as e:
            print(f"âš ï¸ Audio Conversion Error: {e}")
            return None

    def listen_chunk(self, duration=3.0):
        try:
            recording = sd.rec(int(duration * self.rate), samplerate=self.rate,
                               channels=self.channels, device=self.dev, dtype=self.dtype)
            sd.wait()
            return self._convert_to_whisper_format(recording)
        except:
            return None

    def start(self):
        self.data = []

        def cb(indata, *_):
            self.data.append(indata.copy())

        try:
            self.stream = sd.InputStream(samplerate=self.rate, device=self.dev,
                                         channels=self.channels, dtype=self.dtype, callback=cb)
            self.stream.start()
        except:
            pass

    def stop(self):
        try:
            if self.stream: self.stream.stop(); self.stream.close()
        except:
            pass
        if not self.data: return np.array([], dtype=np.float32)
        full_raw = np.concatenate(self.data)
        return self._convert_to_whisper_format(full_raw)

    def smart_listen(self, max_duration=8, silence_duration=0.8, threshold=0.02):
        self.start()
        print("ğŸ¤ Listening...")
        start_time = time.time()
        last_sound_time = time.time()
        has_spoken = False

        while (time.time() - start_time) < max_duration:
            time.sleep(0.05)
            if not self.data: continue
            try:
                recent = self.data[-3:]
                if not recent: continue
                flat = np.concatenate(recent)
                vol = np.max(np.abs(flat))
                if vol > threshold:
                    last_sound_time = time.time()
                    has_spoken = True
                if has_spoken and (time.time() - last_sound_time) > silence_duration:
                    break
            except:
                pass
        return self.stop()


def transcribe_audio(audio_raw):
    if audio_raw is None or stt_model is None or len(audio_raw) < 1000: return None
    try:
        segments, info = stt_model.transcribe(audio_raw, beam_size=1, language="fa")
        text = ""
        for segment in segments:
            text += segment.text + " "
        return text.strip()
    except Exception as e:
        print(f"STT Error: {e}")
        return ""


# ---------------------------------------------------------
# PLAY FUNCTION
# ---------------------------------------------------------
def play(audio_data, sr):
    if audio_data is None: return
    try:
        filepath = None
        if isinstance(audio_data, str) and os.path.exists(audio_data):
            filepath = audio_data
        elif isinstance(audio_data, (np.ndarray, list)):
            unique_id = uuid.uuid4().hex[:8]
            filepath = os.path.join(VOICE_DIR, f"temp_{unique_id}.wav")
            wav = np.array(audio_data)
            max_val = np.max(np.abs(wav))
            if max_val > 0: wav = wav / max_val
            write_wav(filepath, sr, (wav * 32767).astype(np.int16))

        if filepath:
            try:
                if not pygame.mixer.get_init():
                    pygame.mixer.init()
                pygame.mixer.music.load(filepath)
                pygame.mixer.music.play()
                if ROBOT:
                    ROBOT.set_state("talking")
                    while pygame.mixer.music.get_busy():
                        ROBOT.mouth_open = np.random.randint(10, 60)
                        time.sleep(0.1)
                    ROBOT.set_state("idle")
                    ROBOT.mouth_open = 0
            except Exception as e:
                print(f"Audio Play Error: {e}")
    except Exception as e:
        print(f"Play Logic Error: {e}")


# ---------------------------------------------------------
# FACE LOGIN
# ---------------------------------------------------------
def perform_face_login(rec=None):
    global CURRENT_USER_ID, CURRENT_USER_DISPLAY, llm, memory_sys
    known_encodings, known_ids = attendance_sys.load_known_faces()
    video_capture = None
    for idx in [1, 0, 2]:
        cap = cv2.VideoCapture(idx, cv2.CAP_DSHOW)
        if cap.isOpened(): video_capture = cap; break
    if not video_capture: return "Guest", "Guest"

    identified_id = None
    start_time = time.time()
    TIMEOUT = 10
    if ROBOT: ROBOT.set_caption("Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³Ú©Ù† Ú†Ù‡Ø±Ù‡...")

    while identified_id is None:
        if time.time() - start_time > TIMEOUT: break
        ret, frame = video_capture.read()
        if not ret: continue
        small = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
        rgb = np.ascontiguousarray(small[:, :, ::-1])
        faces = face_recognition.face_locations(rgb)
        encs = face_recognition.face_encodings(rgb, faces)
        cv2.imshow("Robot Vision", frame)
        cv2.waitKey(1)

        if len(faces) > 0:
            matches = face_recognition.compare_faces(known_encodings, encs[0], tolerance=0.45)
            detected_id = "Unknown"
            if True in matches:
                first_match_index = matches.index(True)
                detected_id = known_ids[first_match_index]

            if detected_id != "Unknown":
                # ğŸŸ¢ ÙÙ‚Ø· Ø§Ú¯Ø± Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø± Ø§Ù…Ø±ÙˆØ² Ø¨Ø§Ø´Ø¯ True Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
                is_first_time_today = attendance_sys.mark_attendance(detected_id)

                identified_id = detected_id
                saved_persian_name = memory_sys.get_profile_value(detected_id, "name")
                display_name = saved_persian_name if saved_persian_name else detected_id.split('_')[0]

                if ROBOT:
                    ROBOT.set_caption(f"Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯: {display_name}")
                    ROBOT.trigger_nod()
                    # ğŸŸ¢ LOGIC: ÙÙ‚Ø· Ø§Ú¯Ø± Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø± Ø§Ø³Øª Ø³Ù„Ø§Ù… Ú©Ù†
                    if is_first_time_today:
                        if tts: sr, w = tts.synthesize(f"Ø³ÙÙ„Ø§Ù… {display_name}."); play(w, sr)
            else:
                video_capture.release()
                cv2.destroyAllWindows()
                p_name_farsi = ""
                if TEST_TEXT_MODE:
                    print("\n" + "=" * 40)
                    p_name_farsi = input("ğŸ‘‰ NEW USER - ENTER NAME (Farsi): ").strip()
                    print("=" * 40 + "\n")
                else:
                    if tts: sr, w = tts.synthesize("Ø´ÙÙ…Ø§ Ø±Ø§ Ù†ÙÙ…ÛŒØ´ÙÙ†Ø§Ø³ÙÙ…. Ù„ÙØ·ÙØ§Ù‹ Ø§ÙØ³Ù…ÙØªØ§Ù† Ø±Ø§ Ø¨ÙÚ¯ÙˆÛŒÛŒØ¯."); play(w, sr)
                    if ROBOT: ROBOT.set_caption("Ù†Ø§Ù… Ø´Ù…Ø§ Ú†ÛŒØ³ØªØŸ")
                    if rec:
                        audio = rec.smart_listen(max_duration=4)
                        p_name_farsi = transcribe_audio(audio)

                if p_name_farsi and len(p_name_farsi) > 1:
                    base_filename = "User"
                    try:
                        if llm:
                            prompt = f"Convert '{p_name_farsi}' to English letters (Pinglish). One word."
                            base_filename = llm.invoke(prompt).strip().replace(".", "").split()[0]
                    except:
                        base_filename = f"User_{uuid.uuid4().hex[:4]}"

                    print(f"ğŸ“‚ Registering: File={base_filename} | Name={p_name_farsi}")
                    unique_id = attendance_sys.register_student(base_filename, frame, encs[0])
                    memory_sys.update_profile(unique_id, "name", p_name_farsi)

                    identified_id = unique_id
                    display_name = p_name_farsi
                    if tts: sr, w = tts.synthesize(f"Ø®ÙˆØ´Ø¨ÙØ®ØªÙÙ… {p_name_farsi}."); play(w, sr)
                    if ROBOT:
                        ROBOT.set_caption(f"Ø«Ø¨Øª Ø´Ø¯: {display_name}")
                        ROBOT.trigger_nod()
                    return identified_id, display_name
                return "Guest", "Guest"

    if video_capture.isOpened(): video_capture.release()
    cv2.destroyAllWindows()

    final_display = "Guest"
    if identified_id:
        saved = memory_sys.get_profile_value(identified_id, "name")
        final_display = saved if saved else identified_id.split('_')[0]
    return identified_id, final_display


# ---------------------------------------------------------
# ğŸŸ¢ ULTRA-SMART SEARCH (Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø­Ø°Ù Ø´Ø¯Ù‡ Ø¨ÙˆØ¯!)
# ---------------------------------------------------------
def filter_context_by_keywords(full_text, question):
    if not full_text: return ""
    STOPWORDS = ["Ú†ÛŒØ³Øª", "Ú©ÛŒØ³Øª", "Ú©Ø¬Ø§Ø³Øª", "Ú†Ú¯ÙˆÙ†Ù‡", "Ú†Ø·ÙˆØ±", "Ø¢ÛŒØ§", "Ù…Ù†", "ØªÙˆ", "Ø§Ùˆ", "Ù…Ø§", "Ø´Ù…Ø§", "Ø¢Ù†Ù‡Ø§", "Ø§Ø³Øª", "Ù‡Ø³Øª",
                 "Ø¨Ú¯Ùˆ", "ØªÙˆØ¶ÛŒØ­", "Ø¨Ø¯Ù‡", "Ø¯Ø±Ø¨Ø§Ø±Ù‡", "Ù…ÙˆØ±Ø¯", "Ø±Ø§", "Ø¨Ø§", "Ø§Ø²", "Ø¯Ø±", "Ú©Ù‡", "Ùˆ", "Ù‡Ø§", "Ù‡Ø§ÛŒ"]
    words = question.replace("ØŸ", "").replace("!", "").split()
    keywords = [w for w in words if w not in STOPWORDS and len(w) > 2]

    print(f"ğŸ” [SEARCH] Keywords: {keywords}")
    if not keywords: return full_text[:2000]

    lines = full_text.split('\n')
    best_indices = []
    for i, line in enumerate(lines):
        if any(kw in line for kw in keywords):
            best_indices.append(i)

    if not best_indices:
        print("âš ï¸ [SEARCH] No keywords found.")
        return ""

    output = []
    char_count = 0
    MAX_CHARS = 4500
    sorted_indices = sorted(list(set(best_indices)))
    last_idx = -1
    for idx in sorted_indices:
        if char_count >= MAX_CHARS: break
        start = max(0, idx - 2)
        end = min(len(lines), idx + 3)
        for i in range(start, end):
            if i <= last_idx: continue
            line = lines[i].strip()
            if len(line) > 5:
                output.append(line)
                char_count += len(line)
                last_idx = i
            if char_count >= MAX_CHARS: break
    return "\n".join(output)


# ---------------------------------------------------------
# MAIN LOGIC
# ---------------------------------------------------------
def run_ai_logic():
    global stt_model, stt_processor, tts, llm, CURRENT_USER_ID, CURRENT_USER_DISPLAY, LAST_USER

    if ROBOT: ROBOT.set_caption("Loading Brain...")

    try:
        # ğŸŸ¢ Brain Setup
        llm = OllamaLLM(
            model="llama3.1",
            base_url="http://localhost:11434",
            temperature=0.1,
            keep_alive="0m"
        )
        tts = TextToSpeechService()

        if not TEST_TEXT_MODE:
            print("â³ Loading Whisper Model...")
            device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"ğŸš€ Using Device: {device}")
            stt_model = WhisperModel("whisper", device=device, compute_type="float16" if device == "cuda" else "int8")
            print("âœ… Whisper Loaded!")

    except Exception as e:
        print(f"Init Error: {e}")

    rec = Recorder() if not TEST_TEXT_MODE else None
    WAKE_WORDS = ["Ø³Ù„Ø§Ù…", "salam", "slm", "Ø³Ø§Ù„Ø§Ù…", "Ø³Ù„Ø§Ù†", "ØµÙ„Ø§Ù…", "hi", "hello", "Ø¯Ø±ÙˆØ¯", "Ø³Ù„Ù…"]

    print("\nâœ… ROBOT READY")
    if TEST_TEXT_MODE:
        print("ğŸ”´ MODE: TEXT")
    else:
        print("ğŸŸ¢ MODE: VOICE")

    last_class_checked = None
    cached_doc_context = ""

    while ROBOT.running:
        ROBOT.set_state("idle")
        ROBOT.set_caption("Ø¨Ø±Ø§ÛŒ Ø¨ÛŒØ¯Ø§Ø± Ú©Ø±Ø¯Ù† Ø±Ø¨Ø§Øª Ø³Ù„Ø§Ù… Ø¨Ø¯Ù‡")
        wake_detected = False

        # --- WAKE WORD ---
        if TEST_TEXT_MODE:
            text = input("\nWaiting (type 'salam'): ").strip().lower()
            if "salam" in text or "Ø³Ù„Ø§Ù…" in text: wake_detected = True
        else:
            audio_chunk = rec.listen_chunk(duration=2.0)
            if audio_chunk is None: continue
            audio_chunk = np.nan_to_num(audio_chunk)
            text = transcribe_audio(audio_chunk)
            if text:
                print(f"ğŸ¤ HEARD: '{text}'")
                for word in WAKE_WORDS:
                    if word in text.lower(): wake_detected = True; break

        if wake_detected:
            if ROBOT: ROBOT.trigger_nod()
            # âœ… Ø­Ø±Ú©Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ (Ù‡Ù…ÛŒØ´Ù‡ Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯ Ù…Ù† Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ§Ù…)
            if tts: sr, w = tts.synthesize("Ù…ÙÙ† Ø¢Ù…Ø§Ø¯ÙÙ‡â€ŒØ§ÙÙ…."); play(w, sr)

            # 1. FACE RECOGNITION
            ROBOT.set_state("thinking")
            # Ø¯Ø§Ø®Ù„ Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ Ú©Ù‡ Ø³Ù„Ø§Ù… Ú©Ù†Ø¯ ÛŒØ§ Ù†Ù‡
            u_id, u_display = perform_face_login(rec)
            CURRENT_USER_ID = u_id
            CURRENT_USER_DISPLAY = u_display

            if CURRENT_USER_ID != "Guest":
                LAST_USER = CURRENT_USER_ID

            # 2. CLASS CHECK
            user_class = None
            if CURRENT_USER_ID != "Guest":
                user_class = class_sys.get_user_class(CURRENT_USER_ID)
                if not user_class:
                    if tts: sr, w = tts.synthesize("Ú©ÙÙ„Ø§Ø³Ù Ú†ÙÙ†Ø¯ÙÙ…ÛŒØŸ"); play(w, sr)
                    c_text = ""
                    if TEST_TEXT_MODE:
                        c_text = input("ğŸ‘‰ ENTER CLASS: ").strip()
                    else:
                        c_audio = rec.smart_listen(max_duration=5)
                        if c_audio is not None: c_audio = np.nan_to_num(c_audio)
                        c_text = transcribe_audio(c_audio)
                    if c_text:
                        detected_num = class_sys.extract_class_number(c_text)
                        if detected_num:
                            class_sys.set_user_class(CURRENT_USER_ID, detected_num)
                            user_class = detected_num
                            if tts: sr, w = tts.synthesize(f"Ú©ÙÙ„Ø§Ø³Ù {detected_num} Ø«ÙØ¨Øª Ø´ÙØ¯."); play(w, sr)

            if CURRENT_USER_ID != "Guest" and not user_class:
                print("âš ï¸ DEBUG: Auto-assigning Class 5")
                user_class = "5"

            # 3. LOAD DOCUMENTS
            if user_class:
                if user_class != last_class_checked:
                    print(f"\nğŸ“‚ [DEBUG] LOADING CLASS {user_class}...")
                    cached_doc_context = class_sys.get_class_context(user_class)
                    last_class_checked = user_class
                else:
                    print(f"âš¡ [DEBUG] CACHED DATA")

            # 4. LISTEN FOR QUESTION
            ROBOT.set_state("listening")
            ROBOT.set_caption(f"Ú¯ÙˆØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ù…... ({CURRENT_USER_DISPLAY})")

            q_text = ""
            if TEST_TEXT_MODE:
                print("\n" + "=" * 40)
                q_text = input(f"ğŸ‘‰ {CURRENT_USER_DISPLAY}, ASK: ").strip()
                print("=" * 40 + "\n")
            else:
                q_audio = rec.smart_listen(max_duration=10)
                if q_audio is not None:
                    q_audio = np.nan_to_num(q_audio)
                    q_text = transcribe_audio(q_audio)

            if q_text and len(q_text) > 2:
                q_text = q_text.replace("ÙŠ", "ÛŒ").replace("Ùƒ", "Ú©")
                print(f"â“ Question: {q_text}")
                if ROBOT: ROBOT.set_user_question(q_text)

                # =========================================================
                # ğŸš€ 1. FAST REFLEX
                # =========================================================
                FAST_RESPONSES = {
                    "Ø³Ù„Ø§Ù…": "Ø³ÙÙ„Ø§Ù…! Ø®ÙˆØ´Ø­Ø§Ù„ÙÙ… Ù…ÛŒ Ø¨ÛŒÙ†ÙÙ…ÙØª.",
                    "Ø³Ù„Ø§Ù… Ø®ÙˆØ¨ÛŒ": "Ø³ÙÙ„Ø§Ù… Ø¹ÙØ²ÛŒØ²ÙÙ…ØŒ Ù…ÙÙ† Ø¹Ø§Ù„ÛŒâ€ŒØ§ÙÙ…! ØªÙÙˆ Ú†ÙØ·ÙˆØ±ÛŒØŸ",
                    "Ú†Ø·ÙˆØ±ÛŒ": "Ù…ÙÙ…Ù†ÙˆÙ†ØŒ Ù‡ÙÙ…Ù‡ Ú†ÛŒØ² Ù…ÙØ±ÙØªÙ‘ÙØ¨ Ø§ÙØ³Øª.",
                    "Ø®ÙˆØ¨ÛŒ": "Ù…ÙØ±Ø³ÛŒ Ú©ÙÙ‡ Ù¾ÙØ±Ø³ÛŒØ¯ÛŒØŒ Ù…ÙÙ† Ø®ÙˆØ¨ÙÙ….",
                    "Ú†Ù‡ Ø®Ø¨Ø±": "Ø³ÙÙ„Ø§Ù…ÙØªÛŒ! Ù…ÙÙ†ØªÙØ¸ÙØ±Ù Ø³ÙÙˆØ§Ù„Ø§ØªÙ ØªÙÙˆ Ù‡ÙØ³ØªÙÙ….",
                    "Ø®Ø¯Ø§Ø­Ø§ÙØ¸": "Ø¨ÙÙ‡ Ø§ÙÙ…ÛŒØ¯Ù Ø¯ÛŒØ¯Ø§Ø±! Ø®ÙØ¯Ø§Ø­Ø§ÙÙØ¸.",
                    "Ù…Ù…Ù†ÙˆÙ†": "Ø®ÙˆØ§Ù‡ÙØ´ Ù…ÛŒâ€ŒÚ©Ù†ÙÙ… Ø¯ÙˆØ³ØªÙ Ù…ÙÙ†."
                }
                cleaned_q = q_text.replace("ØŸ", "").replace("!", "").strip()
                fast_answer = None
                for key, val in FAST_RESPONSES.items():
                    if key == cleaned_q or q_text.startswith(key + " "):
                        fast_answer = val
                        break

                if fast_answer:
                    print(f"âš¡ Fast Reply: {fast_answer}")
                    if tts: sr, w = tts.synthesize(fast_answer); play(w, sr)
                    time.sleep(0.5)
                    continue

                # =========================================================
                # ğŸ§  2. WHO AM I?
                # =========================================================
                if "Ø§Ø³Ù… Ù…Ù† Ú†ÛŒÙ‡" in q_text or "Ù…Ù† Ú©ÛŒÙ…" in q_text:
                    saved_name = None
                    if CURRENT_USER_ID != "Guest":
                        saved_name = memory_sys.get_profile_value(CURRENT_USER_ID, "name")
                    respond = f"Ø§ÙØ³Ù…Ù Ø´ÙÙ…Ø§ {saved_name} Ø§ÙØ³Øª." if saved_name else "Ù‡ÙÙ†ÙˆØ² Ø§ÙØ³Ù…ÙØª Ø±Ø§ Ù†ÙÙ…ÛŒØ¯Ø§Ù†ÙÙ…."
                    if tts: sr, w = tts.synthesize(respond); play(w, sr)
                    time.sleep(1)
                    continue

                # =========================================================
                # ğŸ’¾ 3. NAME LEARNING
                # =========================================================
                detected_name = ""
                prefixes = ["Ø§Ø³Ù… Ù…Ù†", "Ø§Ø³Ù…Ù…", "Ù…Ù†", "Ù†Ø§Ù… Ù…Ù†"]
                suffixes = ["Ø§Ø³Øª", "Ù‡Ø³ØªÙ…", "Ù‡", "Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯"]
                clean_q = q_text

                if any(p in q_text for p in prefixes) and len(q_text.split()) < 6:
                    for p in prefixes: clean_q = clean_q.replace(p, "")
                    for s in suffixes:
                        clean_q = clean_q.replace(f" {s}", "").strip()
                        if clean_q.endswith(f"{s}"):
                            if s == "Ù‡" and len(clean_q) > 2:
                                clean_q = clean_q[:-1]
                            elif s != "Ù‡":
                                clean_q = clean_q.replace(s, "")
                    clean_q = clean_q.strip()
                    if len(clean_q) > 2 and " " not in clean_q:
                        if clean_q not in ["Ú†ÛŒÙ‡", "Ú©ÛŒÙ‡", "Ú†ÛŒØ³Øª", "Ú©ÛŒØ³Øª"]:
                            detected_name = clean_q

                if detected_name:
                    if CURRENT_USER_ID != "Guest":
                        memory_sys.update_profile(CURRENT_USER_ID, "name", detected_name)
                        CURRENT_USER_DISPLAY = detected_name
                        resp = f"Ú†ÙØ´Ù…ØŒ Ø§ÙØ³Ù…ÙØª Ø±Ø§ Â«{detected_name}Â» Ø°ÙØ®ÛŒØ±ÙÙ‡ Ú©ÙØ±Ø¯ÙÙ…."
                        if tts: sr, w = tts.synthesize(resp); play(w, sr)
                        time.sleep(1)
                        continue

                # =========================================================
                # ğŸ“œ 4. MEMORY RECALL
                # =========================================================
                summary_mode = None
                check_text = q_text.lower()

                if "Ú†ÛŒ Ú¯ÙØªÛŒÙ…" in check_text or "Ú†Ù‡ ØµØ­Ø¨Øª" in check_text or "Ø­Ø±Ù Ø²Ø¯ÛŒÙ…" in check_text or "Ù…Ø±ÙˆØ±" in check_text or "Ø®Ù„Ø§ØµÙ‡" in check_text:
                    if "Ø§Ù…Ø±ÙˆØ²" in check_text:
                        summary_mode = "today"
                    else:
                        summary_mode = "all"

                if summary_mode:
                    if CURRENT_USER_ID == "Guest":
                        resp = "Ù…ÙÙ† Ø­Ø§ÙÙØ¸ÙÙ‡â€ŒØ§ÛŒ Ø§ÙØ² Ø´ÙÙ…Ø§ Ù†ÙØ¯Ø§Ø±ÙÙ… Ú†ÙˆÙ† Ù‡ÙÙ†ÙˆØ² Ø«ÙØ¨ØªÙâ€ŒÙ†Ø§Ù… Ù†ÙÚ©ÙØ±Ø¯ÙÙ‡â€ŒØ§ÛŒØ¯."
                    else:
                        ROBOT.set_state("thinking")
                        ROBOT.set_caption("Ø¯Ø± Ø­Ø§Ù„ Ù…Ø±ÙˆØ± Ø®Ø§Ø·Ø±Ø§Øª...")
                        logs = memory_sys.get_conversation_log(CURRENT_USER_ID, mode=summary_mode)
                        if not logs:
                            resp = "Ù…Ø§ Ø§ÙÙ…Ø±ÙˆØ² Ù‡ÙÙ†ÙˆØ² ØµÙØ­Ø¨ÙØªÛŒ Ù†ÙÚ©ÙØ±Ø¯ÛŒÙ…." if summary_mode == "today" else "Ù…ÙÙ† Ù‡ÙÙ†ÙˆØ² Ú†ÛŒØ²ÛŒ ÛŒØ§Ø¯ÙÙ… Ù†ÙÙ…ÛŒâ€ŒØ¢ÛŒÙØ¯."
                        else:
                            prompt = (
                                f"System: You are a helpful assistant. The user is asking to recall past conversations.\n"
                                f"Task: Based on the LOGS below, summarize what you and the user talked about in Persian (Farsi).\n"
                                f"Rules: Keep it brief, friendly, and in bullet points if possible. Say 'Ù…Ø§ Ø¯Ø± Ù…ÙˆØ±Ø¯ ... ØµØ­Ø¨Øª Ú©Ø±Ø¯ÛŒÙ…'.\n\n"
                                f"LOGS:\n{logs}\n\n"
                                f"Assistant:"
                            )
                            try:
                                print("ğŸ“œ Generating Summary...")
                                resp = llm.invoke(prompt).strip()
                            except Exception as e:
                                resp = "Ù…ÙØªØ§Ø³ÙÙØ§Ù†ÙÙ‡ Ù†ÙØªÙÙˆØ§Ù†ÙØ³ØªÙÙ… Ø®Ø§Ø·ÙØ±Ø§Øª Ø±Ø§ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ú©ÙÙ†ÙÙ…."

                    print(f"ğŸ¤– MemoryBot: {resp}")

                    if not resp.endswith((".", "!", "?", "ØŸ")): resp += "."

                    # ğŸŸ¢ Ø§Ø¹Ù…Ø§Ù„ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ØªÙ„ÙØ¸ Ø±ÙˆÛŒ Ø­Ø§ÙØ¸Ù‡ Ù‡Ù…
                    tts_text = fix_pronunciation(resp)

                    forbidden_chars = ["*", "_", "+", "-", "="]
                    for char in forbidden_chars: tts_text = tts_text.replace(char, " ")
                    tts_text = tts_text.replace("\n", ". ")

                    if tts: sr, w = tts.synthesize(tts_text); play(w, sr)
                    time.sleep(1)
                    continue

                # =========================================================
                # ğŸ¤– 5. AI GENERATION (TEACHING MODE)
                # =========================================================
                ROBOT.set_state("thinking")
                final_context = ""
                if cached_doc_context:
                    relevant_snippet = filter_context_by_keywords(cached_doc_context, q_text)
                    if relevant_snippet: final_context = relevant_snippet

                prompt = (
                    f"System: You are a helpful Persian teaching assistant. Respond ONLY in Farsi.\n"
                    f"Task: Answer the user question based on the Context below.\n"
                    f"Rules:\n"
                    f"1. Use short sentences. Use commas (ØŒ) and periods (.) frequently to ensure clear speech.\n"
                    f"2. If answer is in Context, say: 'SOURCE: Document'. Then answer.\n"
                    f"3. If answer is NOT in Context, use your own knowledge and say: 'SOURCE: Knowledge'. Then answer accurately.\n"
                    f"4. Do NOT hallucinate. Elephants do NOT live in water.\n\n"
                    f"Context:\n{final_context}\n\n"
                    f"User: {q_text}\n"
                    f"Assistant:"
                )

                try:
                    ans = llm.invoke(prompt, stop=["### User:", "User:"]).strip()
                    print(f"\nğŸ§  [DEBUG] RAW: {ans}\n")

                    garbage = ["<|im_end|>", "<|im_start|>", "System:", "User:", "Assistant:", "###"]
                    for g in garbage: ans = ans.replace(g, "")

                    final_spoken_text = ans.replace("SOURCE: Document", "") \
                        .replace("SOURCE: Knowledge", "") \
                        .replace("SOURCE: General Knowledge", "") \
                        .replace("SOURCE:", "") \
                        .strip()

                    # ğŸŸ¢ 1. Ø§Ø¹Ù…Ø§Ù„ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ØªÙ„ÙØ¸ (Ù…Ù‡Ù…ØªØ±ÛŒÙ† Ø¨Ø®Ø´)
                    tts_text = fix_pronunciation(final_spoken_text)

                    # ğŸŸ¢ 2. Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ø§Ù…Ø§ Ø§Ø² Ú©Ù„Ù…Ø§Øª
                    tts_text = tts_text.replace("ØŒ", " ØŒ ")
                    tts_text = tts_text.replace(",", " , ")

                    forbidden_chars = ["*", "_", "+", "-", "="]
                    for char in forbidden_chars:
                        tts_text = tts_text.replace(char, " ")

                    tts_text = tts_text.replace("\n", ". ")
                    tts_text = re.sub(r'[a-zA-Z]', '', tts_text)
                    tts_text = re.sub(r'\d+\.', '', tts_text)
                    tts_text = tts_text.replace("(", " ").replace(")", " ")
                    tts_text = re.sub(r'\s+', ' ', tts_text).strip()

                    # ØªØ¶Ù…ÛŒÙ† Ù†Ù‚Ø·Ù‡
                    if tts_text and not tts_text.endswith((".", "!", "?", "ØŸ")):
                        tts_text += "."

                    print(f"ğŸ—£ï¸ TTS CLEAN: {tts_text}")

                    if tts_text:
                        raw_sentences = re.split(r'([.?!ØŸ])', tts_text)
                        sentences = []
                        temp_sent = ""

                        for part in raw_sentences:
                            if part.strip() in [".", "?", "!", "ØŸ"]:
                                temp_sent += part
                                sentences.append(temp_sent.strip())
                                temp_sent = ""
                            else:
                                temp_sent += part
                        if temp_sent.strip(): sentences.append(temp_sent.strip())

                        for sent in sentences:
                            if len(sent) > 1 and any(c >= 'Ø¢' and c <= 'ÛŒ' for c in sent):
                                if not sent.endswith((".", "!", "?", "ØŸ")): sent += "."
                                print(f"Sound Chunk: {sent}")
                                if tts:
                                    sr, w = tts.synthesize(sent)
                                    play(w, sr)

                    should_save = True
                    if "Ù…ØªÙˆØ¬Ù‡ Ù†Ø´Ø¯Ù…" in tts_text: should_save = False
                    if CURRENT_USER_ID != "Guest" and should_save:
                        memory_sys.save_interaction(CURRENT_USER_ID, q_text, tts_text)

                except Exception as e:
                    print(f"âŒ AI Error: {e}")
                    traceback.print_exc()

            else:
                if ROBOT: ROBOT.trigger_shake()

            time.sleep(0.5)


if __name__ == "__main__":
    ROBOT = robot_gui.RobotUI()
    t = threading.Thread(target=run_ai_logic)
    t.daemon = True
    t.start()
    ROBOT.run()
